{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPSSkOYmbiSf"
      },
      "source": [
        "### Libraries to be used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HK-M13rRZ_Rk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.cluster import KMeans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcL0TT0bbclZ"
      },
      "source": [
        "Reading the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sm8T8nidbMRY"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"Dataset of Diabetes .csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Examining the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NPoZEnUFbpGc",
        "outputId": "1de74575-54c3-419b-bcdb-90a214c60581"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xnhcqzz5bwRN",
        "outputId": "9aa3a4d7-2f04-4787-e097-22a0b6cc187d"
      },
      "outputs": [],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, we have 1000 rows(data) that we will work on, also we have two nominal data columns(Gender and Class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also have two columns that we won't be using during the trainig phase(ID and No_Pation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8F0u56ygbyUk",
        "outputId": "dc93b882-672c-47d7-a1dc-25180df241c6"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have a dataset containing 14 columns and 1000 rows with no missing values. Out of the 14 columns, 12 are numerical and likely won't require encoding, while the remaining 2 are of object type and may need to be encoded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "NvtZge0xcHH-",
        "outputId": "135a26b6-0a0e-49f2-e29e-275d918978e4"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check for null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "Rjzwj3h-cIzC",
        "outputId": "2f95b4e7-658a-4d15-d1c0-38f4d46cd0ef"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "No null values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's check for duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "duplicates = df.duplicated()\n",
        "print(duplicates.sum())\n",
        "df[df.duplicated()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see we don't have any duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1IrhoWncV4K"
      },
      "source": [
        "Let's drop useless columns, such as id and No_Pation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Instead of dropping data from original dataset, we will use the iloc method and save the data to be used in new variable called df_cleaned, that we will be using from now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_cleaned = df.iloc[:,2:]\n",
        "df_cleaned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgCGf_o7c0WD"
      },
      "source": [
        "### Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_Gender = LabelEncoder()\n",
        "label_Class = LabelEncoder()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check original unique values before mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Original unique values in 'Gender':\", df_cleaned['Gender'].unique())\n",
        "print(\"Original unique values in 'CLASS':\", df_cleaned['CLASS'].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, we have some errors in the data entry, we have 'F' and 'f', we also have 'N' and 'N ', ...etc\n",
        "all of this need to be fixed before encoding these nominal data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First in 'Gender'; we have females and Males, so we must have encoded values of 'F' and 'M', let's handle this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove spaces and convert to upper case\n",
        "df_cleaned['Gender'] = df_cleaned['Gender'].str.strip().str.upper()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Original unique values in 'Gender':\", df_cleaned['Gender'].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now in 'CLASS'; we shall have unique values of Diabetic, Non-Diabetic, or Predict-Diabetic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_cleaned['CLASS'] = df_cleaned['CLASS'].str.strip().str.upper()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Original unique values in 'CLASS':\", df_cleaned['CLASS'].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's move on to the next part and encode these values, we shall have encoded values of 0 and 1 in the Gender attribute and 0, 1 and 2 in the CLASS attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_cleaned[\"Gender\"] = label_Gender.fit_transform(df_cleaned[\"Gender\"])\n",
        "df_cleaned[\"CLASS\"] = label_Class.fit_transform(df_cleaned[\"CLASS\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Unique values in 'Gender':\", df_cleaned['Gender'].unique())\n",
        "print(\"Unique values in 'CLASS':\", df_cleaned['CLASS'].unique())\n",
        "print(\"\\nGender mapping:\")\n",
        "for num, cat in enumerate(label_Gender.classes_):\n",
        "    print(f\"{num} -> {cat}\")\n",
        "print(\"\\nClass mapping:\")\n",
        "for num, cat in enumerate(label_Class.classes_):\n",
        "    print(f\"{num} -> {cat}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogSsRAAmdgjv"
      },
      "source": [
        "### Outlier Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will start by plotting the box plot for each attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attributes = ['Gender', 'AGE', 'Urea', 'Cr', 'HbA1c', 'Chol', 'TG', 'HDL', 'LDL', 'VLDL', 'BMI', 'CLASS']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16, 12))\n",
        "\n",
        "for i, col in enumerate(attributes, start=1):\n",
        "    plt.subplot(3, 4, i)\n",
        "    sns.boxplot(y=df_cleaned[col])\n",
        "    plt.title(f'Box Plot - {col}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We want 'apply' outlier detection on Gender and Class attributes as this is nonsense, outliers only make sense for continuous data as they’re values that are way off the usual range, but Gender (0/1) and CLASS (0/1/2) are categories encoded as numbers, not continuous numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_outliers_iqr(data, columns):\n",
        "    mask = pd.Series([True] * len(data))\n",
        "    initial_len = len(data)\n",
        "    for column in columns:\n",
        "        Q1 = data[column].quantile(0.25)\n",
        "        Q3 = data[column].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower = Q1 - 1.5 * IQR\n",
        "        upper = Q3 + 1.5 * IQR\n",
        "        col_mask = (data[column] >= lower) & (data[column] <= upper)\n",
        "        removed = (~col_mask).sum()\n",
        "        print(f\"Outliers removed in '{column}': {removed}\")\n",
        "        mask &= col_mask\n",
        "    final_len = mask.sum()\n",
        "    print(f\"\\nTotal rows after outlier removal: {final_len} (removed {initial_len - final_len} rows)\")\n",
        "    return data[mask]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The mask used lets us check all columns at once on the full dataset before removing anything, instead of removing  down the data repeatedly, this way we avoid accidentally removing too many rows as outliers are multidimensional, a row might look like an outlier on column A alone, but if columns B and C values are perfectly normal, we might want to reconsider. \n",
        "Filtering column by column and reducing the dataframe after each step can over-filter — throwing out rows that would pass a combined all-columns check."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numerical_columns = ['AGE', 'Urea', 'Cr', 'HbA1c', 'Chol', 'TG', 'HDL', 'LDL', 'VLDL', 'BMI']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_cleaned = remove_outliers_iqr(df_cleaned, numerical_columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's plot once again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16, 12))\n",
        "\n",
        "for i, col in enumerate(attributes, start=1):\n",
        "    plt.subplot(3, 4, i)\n",
        "    sns.boxplot(y=df_cleaned[col])\n",
        "    plt.title(f'Box Plot - {col}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_cleaned[numerical_columns] = scaler.fit_transform(df_cleaned[numerical_columns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n----- SCALED FEATURES PREVIEW -----\")\n",
        "print(df_cleaned.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Final Dataset Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_cleaned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Feature Correlation Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(df_cleaned.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Gender VS Class percentage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gender_dist = df_cleaned.groupby(['Gender', 'CLASS']).size().unstack().fillna(0)\n",
        "gender_dist_pct = gender_dist.div(gender_dist.sum(axis=1), axis=0) * 100\n",
        "\n",
        "gender_dist_pct.plot(kind='bar', stacked=True, colormap='coolwarm')\n",
        "plt.title(\"Diabetes Class Distribution by Gender (%)\")\n",
        "plt.ylabel(\"Percentage\")\n",
        "plt.xticks(ticks=[0, 1], labels=['Male', 'Female'], rotation=0)\n",
        "plt.legend(title='CLASS', labels=['Non-Diabetic', 'Predict-Diabetic', 'Diabetic'])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Age Group vs Diabetes percentage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_cleaned['AgeGroup'] = pd.cut(df_cleaned['AGE'], bins=[0, 0.3, 0.6, 1.0], labels=['Young', 'Middle-Aged', 'Older'])\n",
        "age_dist = df_cleaned.groupby(['AgeGroup', 'CLASS']).size().unstack().fillna(0)\n",
        "age_dist_pct = age_dist.div(age_dist.sum(axis=1), axis=0) * 100\n",
        "\n",
        "age_dist_pct.plot(kind='bar', stacked=True, colormap='viridis')\n",
        "plt.title(\"Diabetes Class Distribution by Age Group (%)\")\n",
        "plt.ylabel(\"Percentage\")\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(title='CLASS', labels=['Non-Diabetic', 'Predict-Diabetic', 'Diabetic'])\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Yz927n_fBWm"
      },
      "source": [
        "### Training Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Agglomerative Model (unsupervised)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_clustering = df_cleaned.drop('CLASS', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "agglo_complete = AgglomerativeClustering(\n",
        "    n_clusters=3,\n",
        "    linkage='complete',\n",
        "    metric='euclidean' \n",
        ")\n",
        "\n",
        "agglo_single = AgglomerativeClustering(\n",
        "    n_clusters=3,\n",
        "    linkage='single',\n",
        "    metric='euclidean'\n",
        ")\n",
        "\n",
        "cluster_labels_complete = agglo_complete.fit(X_clustering)\n",
        "cluster_labels_single = agglo_single.fit(X_clustering)\n",
        "print(len(agglo_complete.labels_))\n",
        "print((agglo_complete.labels_))\n",
        "print(len(agglo_single.labels_))\n",
        "print((agglo_single.labels_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "linked_complete = linkage(X_clustering, method='complete', metric='euclidean')\n",
        "plt.figure(figsize=(8, 4))\n",
        "dendrogram(linked_complete)\n",
        "plt.title(\"Dendrogram (Complete Linkage)\")\n",
        "plt.show()\n",
        "\n",
        "# Single linkage dendrogram\n",
        "linked_single = linkage(X_clustering, method='single', metric='euclidean')\n",
        "plt.figure(figsize=(8, 4))\n",
        "dendrogram(linked_single)\n",
        "plt.title(\"Dendrogram (Single Linkage)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### K-Means\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)  \n",
        "kmeans.fit(X_clustering)\n",
        "\n",
        "labels = kmeans.labels_\n",
        "centers = kmeans.cluster_centers_\n",
        "#print(X_clustering)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(labels)\n",
        "unique, counts = np.unique(labels, return_counts=True)\n",
        "result = dict(zip(unique, counts))\n",
        "print(result)\n",
        "print(df_cleaned['CLASS'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.optimize import linear_sum_assignment\n",
        "# Example data (replace with yours)\n",
        "y_true = df_cleaned[\"CLASS\"]\n",
        "y_pred = labels\n",
        "\n",
        "# Build confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Hungarian algorithm to find best mapping\n",
        "row_ind, col_ind = linear_sum_assignment(-cm)\n",
        "\n",
        "# Create mapping dict\n",
        "mapping = {pred_label: true_label for pred_label, true_label in zip(col_ind, row_ind)}\n",
        "\n",
        "# Map predictions to true labels\n",
        "mapped_preds = np.array([mapping[label] for label in y_pred])\n",
        "\n",
        "print(\"Best mapping:\", mapping)\n",
        "mapped_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "as we can see, now we have the changed labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "acc = accuracy_score(y_true, mapped_preds)\n",
        "cm = confusion_matrix(y_true, mapped_preds)\n",
        "report = classification_report(y_true, mapped_preds)\n",
        "\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(\"Classification Report:\\n\", report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = df_cleaned.drop('CLASS', axis='columns')\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = df_cleaned['CLASS']\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training multiple models in a pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKxD2-E8fJEL"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"SVM\": SVC(),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"Naive Bayes\": GaussianNB()\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AftAszZJfT00"
      },
      "outputs": [],
      "source": [
        "performance = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(x_train, y_train)\n",
        "    preds = model.predict(x_test)\n",
        "    performance[name] = {\n",
        "        \"Accuracy\": accuracy_score(y_test, preds),\n",
        "        \"Report\": classification_report(y_test, preds),\n",
        "        \"Confusion Matrix\": confusion_matrix(y_test, preds)\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbEWQIDlkEkv"
      },
      "source": [
        "### Performance Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5VQMrWrfiCt",
        "outputId": "ec8c7d8c-da91-490f-d059-e5d061b7a9b5"
      },
      "outputs": [],
      "source": [
        "for name, metrics in performance.items():\n",
        "    print(f\"\\n{name} - Accuracy: {metrics['Accuracy']:.4f}\")\n",
        "    print(\"Classification Report:\\n\", metrics[\"Report\"])\n",
        "    print(\"Confusion Matrix:\\n\", metrics[\"Confusion Matrix\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTSR70NJy1og"
      },
      "source": [
        "### Visualize Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "B2CBCQxoy17x",
        "outputId": "80d9cede-ecf3-4af8-8af7-3bbef86da62a"
      },
      "outputs": [],
      "source": [
        "acc_df = pd.DataFrame({name: [metrics[\"Accuracy\"]] for name, metrics in performance.items()}, index=[\"Accuracy\"]).T\n",
        "acc_df.plot(kind='barh', legend=False, color='teal')\n",
        "plt.title(\"Model Accuracy Comparison\")\n",
        "plt.xlabel(\"Accuracy\")\n",
        "plt.xlim(0, 1)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaZ2W_QdkTnQ"
      },
      "source": [
        "Feature Importance (Random Forest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "3AvpW9DIkPut",
        "outputId": "44534f2c-9719-45d8-9e9c-f3719f208e12"
      },
      "outputs": [],
      "source": [
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(x, y)\n",
        "importances = pd.Series(rf_model.feature_importances_, index=x.columns)\n",
        "\n",
        "importances.sort_values().plot(kind='barh', color='skyblue', figsize=(10, 6))\n",
        "plt.title(\"Feature Importance (Random Forest)\")\n",
        "plt.xlabel(\"Importance Score\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPBhA4+2rp3l9aeeK8copss",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
